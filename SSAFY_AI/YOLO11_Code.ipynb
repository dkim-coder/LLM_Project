{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08ef713-2de6-4e9c-a306-6586a374d77a",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 설치 및 불러오기  \n",
    "YOLO 모델을 실행하기 위한 환경을 구성하는 코드입니다.  \n",
    "필요한 패키지를 설치하고, 이미지 처리 및 데이터 로딩에 필요한 라이브러리를 불러옵니다.\n",
    "\n",
    "> ✅ 설치 패키지\n",
    "- `ultralytics`: YOLO 모델 실행 및 학습\n",
    "- `opencv-python`: 이미지 로딩 및 전처리\n",
    "- `numpy`, `matplotlib`: 데이터 처리 및 시각화\n",
    "\n",
    "> ✅ 불러오는 핵심 라이브러리\n",
    "- `torch`, `torchvision`: 모델 학습 및 데이터 전처리\n",
    "- `ultralytics.YOLO`: YOLO 모델 로딩\n",
    "- `cv2`, `numpy`: 이미지 처리 및 수치 계산\n",
    "- `tqdm`, `matplotlib.pyplot`: 시각화 및 진행 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35203ed-0460-416e-af19-1afda7596d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics opencv-python numpy matplotlib tqdm pyyaml -q\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from ultralytics import YOLO\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d116de0e-b972-4e9e-a0b6-b27180ccd59a",
   "metadata": {},
   "source": [
    "## 2. 랜덤 시드 고정\n",
    "\n",
    "실험의 일관성을 유지하기 위해 `random`, `numpy`, `torch`의 시드를 고정합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e093257-b099-4663-834d-3e2191e2690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259a704a-027e-4dc8-8da9-1fd0eaf27f41",
   "metadata": {},
   "source": [
    "## 3. 데이터 경로 설정 및 YAML 파일 로드\n",
    "`data.yaml` 파일을 불러와 학습(train), 검증(val) 데이터의 경로를 설정합니다.\n",
    "\n",
    "> ✅ 학습 데이터는 모델을 학습시키는 데 사용되며,  \n",
    "> ✅ 검증 데이터는 학습 중 모델의 성능을 평가하고 과적합 여부를 확인하는 데 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343acdc6-ff25-4a0d-bcbe-d94c83c30325",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_YAML_PATH = \"/kaggle/input/pothole-detection-challenge/data.yaml\"\n",
    "\n",
    "with open(DATA_YAML_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    data_yaml = yaml.safe_load(f)\n",
    "\n",
    "DATASET_PATH = os.path.dirname(DATA_YAML_PATH)\n",
    "TRAIN_IMAGES = os.path.join(DATASET_PATH, data_yaml[\"train\"].replace(\"../\", \"\"))\n",
    "VALID_IMAGES = os.path.join(DATASET_PATH, data_yaml[\"val\"].replace(\"../\", \"\"))\n",
    "\n",
    "print(DATASET_PATH)\n",
    "print(TRAIN_IMAGES)\n",
    "print(VALID_IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4816e926-18d6-43ff-b5ac-59ef099d4037",
   "metadata": {},
   "source": [
    "## 4. 데이터셋 클래스 정의 및 로드  \n",
    "객체 탐지 모델을 위한 이미지 데이터셋을 생성하고 불러오는 과정입니다.  \n",
    "OpenCV와 glob을 활용하여 이미지를 로드하고, torchvision.transforms를 적용해  \n",
    "크기 변환 및 텐서 변환을 수행합니다.  \n",
    "마지막으로 샘플 이미지를 시각화하여 데이터가 올바르게 불러와졌는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a4cb5a-eec4-497d-be3f-83bf1eae610c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class PotholeDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_paths = glob(os.path.join(image_dir, \"*.jpg\"))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.image_paths[idx])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        return self.transform(img) if self.transform else img\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(PotholeDataset(TRAIN_IMAGES, transform), batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(PotholeDataset(VALID_IMAGES, transform), batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "def show_sample_images(image_loader):\n",
    "    sample_images = next(iter(image_loader))\n",
    "\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "    for i, img in enumerate(sample_images[:6]):\n",
    "        ax[i // 3, i % 3].imshow(img.permute(1, 2, 0).numpy())\n",
    "        ax[i // 3, i % 3].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"훈련 데이터 샘플\")\n",
    "show_sample_images(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9cf97e",
   "metadata": {},
   "source": [
    "## 5. 랜덤 샘플 시각화 (이미지 + 라벨)\n",
    "\n",
    "학습 이미지 중 하나를 랜덤으로 선택하여 해당 이미지와 라벨 정보를 시각화합니다.  \n",
    "라벨은 YOLO 포맷의 좌표 정보를 바탕으로 이미지 위에 바운딩 박스를 그려 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca40583",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"/kaggle/input/pothole-detection-challenge/train/images\"\n",
    "IMAGE_PATHS = sorted(glob(os.path.join(IMAGE_DIR, \"*.jpg\")))\n",
    "\n",
    "IMG_PATH = random.choice(IMAGE_PATHS)\n",
    "LABEL_PATH = IMG_PATH.replace(\"images\", \"labels\").replace(\".jpg\", \".txt\")\n",
    "\n",
    "img = cv2.imread(IMG_PATH)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "h, w, _ = img.shape\n",
    "\n",
    "if os.path.exists(LABEL_PATH):\n",
    "    with open(LABEL_PATH, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            cls, cx, cy, bw, bh = map(float, line.strip().split())\n",
    "            x1 = int((cx - bw / 2) * w)\n",
    "            y1 = int((cy - bh / 2) * h)\n",
    "            x2 = int((cx + bw / 2) * w)\n",
    "            y2 = int((cy + bh / 2) * h)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 5)\n",
    "            cv2.putText(img, f\"Class {int(cls)}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 1)\n",
    "else:\n",
    "    print(\"라벨 파일이 존재하지 않습니다:\", LABEL_PATH)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(os.path.basename(IMG_PATH))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4704726-43ef-4435-b8ad-fb9ad168dfce",
   "metadata": {},
   "source": [
    "## 6. YOLO 모델 학습  \n",
    "YOLO 모델을 불러와 학습을 수행하는 코드입니다.  \n",
    "데이터셋 경로를 지정하고, 에포크 수 및 배치 크기를 설정하여 학습을 진행합니다.\n",
    "- 기본적으로 YOLO 학습 결과는 `runs/detect/train` 디렉토리에 저장됩니다.  \n",
    "- 캐글 환경에서는 저장 경로를 직접 지정해야 합니다.\n",
    "- `project` 및 `name` 파라미터를 사용하여 원하는 경로에 저장할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad5916-b92e-43d8-863d-2d3ddfeb8572",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11l.pt\")\n",
    "\n",
    "def train_model():\n",
    "    results = model.train(\n",
    "        data=DATA_YAML_PATH,\n",
    "        epochs=50,\n",
    "        imgsz=640,\n",
    "        batch=8,\n",
    "        workers=4,\n",
    "        device=\"0\",\n",
    "        project=\"/kaggle/working\",\n",
    "        name=\"pothole_yolo11l_train\",\n",
    "        patience=10,\n",
    "        save_period=10\n",
    "    )\n",
    "    return results\n",
    "\n",
    "results = train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7668279-eae3-4232-b95d-6a2e1cf31333",
   "metadata": {},
   "source": [
    "## 7. 학습 결과 시각화\n",
    "\n",
    "YOLO 모델 학습 과정에서 저장된 손실 그래프(`results.png`)를 불러와 시각화하는 코드입니다.  \n",
    "`matplotlib`을 사용하여 이미지를 출력하고, 그래프 외 요소는 제거하여 깔끔하게 보여줍니다.\n",
    "\n",
    "- 기본적으로 학습 결과는 `runs/detect/train` 디렉토리에 저장됩니다.  \n",
    "- 캐글 환경에서는 저장된 경로를 명시적으로 지정해주어야 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b6ff02-1505-4ded-93d3-2d4c9294f6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RUN_DIR = \"/kaggle/working/pothole_yolo11l_train\"\n",
    "loss_plot_path = f\"{TRAIN_RUN_DIR}/results.png\"\n",
    "\n",
    "img = plt.imread(loss_plot_path)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Loss Graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83538f09-2bc5-429f-9b38-264d61fcef56",
   "metadata": {},
   "source": [
    "## 8. 모델 성능 평가  \n",
    "학습된 YOLO 모델을 불러와 검증 데이터셋을 이용해 성능을 평가하는 코드입니다.  \n",
    "`val()` 함수를 사용하여 `mAP`, `Precision`, `Recall` 등의 성능 지표를 계산합니다.\n",
    "\n",
    "- 캐글 환경에서는 모델이 저장된 경로를 지정해줘야 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1c126-ab8d-4c6c-b53b-88dc07563bfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = YOLO(\"/kaggle/working/pothole_yolo11l_train/weights/best.pt\")\n",
    "\n",
    "val_results = model.val(data=DATA_YAML_PATH, split=\"val\")\n",
    "\n",
    "print(\"검증 데이터 평가 결과:\")\n",
    "print(f\"mAP50: {val_results.box.map50:.4f}\")\n",
    "print(f\"mAP50-95: {val_results.box.map:.4f}\")\n",
    "print(f\"Precision: {val_results.box.mp:.4f}\")\n",
    "print(f\"Recall: {val_results.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06265be",
   "metadata": {},
   "source": [
    "## 9. 모델 추론 및 시각화\n",
    "학습된 YOLO 모델을 사용하여 테스트 데이터셋에서 임의의 이미지를 추론합니다.\n",
    "\n",
    "- 포트홀을 감지하지 못하면 아무것도 표시되지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d222bb-00d5-4bec-b382-1382daf35541",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"/kaggle/working/pothole_yolo11l_train/weights/best.pt\")\n",
    "\n",
    "TEST_IMAGE_DIR = \"/kaggle/input/pothole-detection-challenge/test/images\"\n",
    "test_image_paths = sorted(glob(os.path.join(TEST_IMAGE_DIR, \"*.jpg\")))\n",
    "test_img_path = random.choice(test_image_paths)\n",
    "\n",
    "results = model.predict(source=test_img_path, conf=0.25, imgsz=640, save=False)\n",
    "\n",
    "result_img = results[0].plot()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(result_img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Inference Result: {os.path.basename(test_img_path)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4413d5",
   "metadata": {},
   "source": [
    "## 10. 제출 파일 생성 (submission.csv)\n",
    "테스트 이미지에 대해 학습된 YOLO 모델을 사용하여 객체 탐지를 수행하고,  \n",
    "예측 결과를 제출 형식에 맞춰 `submission.csv` 파일로 저장합니다.\n",
    "\n",
    "- 한 이미지당 박스 하나만 제출하며, confidence가 가장 높은 박스를 사용합니다.\n",
    "- 객체를 감지하지 못한 경우, `ClassId`와 바운딩 박스 좌표는 모두 0으로 처리합니다.\n",
    "- 이미지가 손상되었거나 열리지 않는 경우에도 에러 없이 넘어가도록 예외 처리를 포함합니다.\n",
    "- Output 경로인 /kagggle/working/에 저장됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65db780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "model = YOLO(\"/kaggle/working/pothole_yolo11l_train/weights/best.pt\")\n",
    "\n",
    "TEST_IMG_DIR = \"/kaggle/input/pothole-detection-challenge/test/images\"\n",
    "test_image_paths = sorted(glob(os.path.join(TEST_IMG_DIR, \"*.jpg\")))\n",
    "\n",
    "submission_rows = []\n",
    "\n",
    "for img_path in test_image_paths:\n",
    "    image_id = os.path.basename(img_path)\n",
    "\n",
    "    if cv2.imread(img_path) is None:\n",
    "        print(f\"이미지 로드 실패: {image_id}\")\n",
    "        submission_rows.append({\n",
    "            \"ImageId\": image_id,\n",
    "            \"ClassId\": 0,\n",
    "            \"X\": 0,\n",
    "            \"Y\": 0,\n",
    "            \"Width\": 0,\n",
    "            \"Height\": 0,\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    results = model.predict(source=img_path, conf=0.25, imgsz=640, save=False)\n",
    "    result = results[0]\n",
    "\n",
    "    if len(result.boxes) > 0:\n",
    "        boxes = result.boxes\n",
    "        best_idx = boxes.conf.argmax().item()\n",
    "        cls_id = int(boxes.cls[best_idx].item())\n",
    "        cx, cy, w, h = boxes.xywhn[best_idx].tolist()\n",
    "\n",
    "        submission_rows.append({\n",
    "            \"ImageId\": image_id,\n",
    "            \"ClassId\": cls_id,\n",
    "            \"X\": round(cx, 6),\n",
    "            \"Y\": round(cy, 6),\n",
    "            \"Width\": round(w, 6),\n",
    "            \"Height\": round(h, 6),\n",
    "        })\n",
    "    else:\n",
    "        submission_rows.append({\n",
    "            \"ImageId\": image_id,\n",
    "            \"ClassId\": 0,\n",
    "            \"X\": 0,\n",
    "            \"Y\": 0,\n",
    "            \"Width\": 0,\n",
    "            \"Height\": 0,\n",
    "        })\n",
    "\n",
    "submission_df = pd.DataFrame(submission_rows, columns=[\"ImageId\", \"ClassId\", \"X\", \"Y\", \"Width\", \"Height\"])\n",
    "submission_path = \"/kaggle/working/submission.csv\"\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"제출 파일 저장 완료: {submission_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
